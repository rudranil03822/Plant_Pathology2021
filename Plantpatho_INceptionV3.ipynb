{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Plantpatho_INceptionV3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwldYW6axqix"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lVatCqI34di",
        "outputId": "127347f8-67ce-44bc-acfc-9ca78ccb21e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzOX0hbQ9qjb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE94dP1u923Y"
      },
      "source": [
        "**Importing Important modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTwUEznfgRqZ"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import cv2\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLmV_La5-GL2"
      },
      "source": [
        "***Importing the array of cropped images as csv file***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqbvXzm4SlTe"
      },
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/img.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyHexSTc-ZY6"
      },
      "source": [
        "Normalizing the RGB values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr0Cli2nqns8"
      },
      "source": [
        "df=df/255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti29TR7u3Bg8"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkc1silq-lVQ"
      },
      "source": [
        "storing the images as numpy array reshaping it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzF7e1Ibg6j5"
      },
      "source": [
        "X=np.asarray(df)\n",
        "X=X.reshape(18632,100,100,3)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5St6xYth-0JS"
      },
      "source": [
        "Importing Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q-u4ab_rFI0"
      },
      "source": [
        "df_train=pd.read_csv('/content/drive/MyDrive/train.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggIo64LN-6kx"
      },
      "source": [
        "**Splitting the labels into 6 classes and encoding it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar5TZoo0rXOv"
      },
      "source": [
        "df_train[\"labels\"]=df_train[\"labels\"].apply(lambda x:x.split(\" \"))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAUTLTlbrbUS"
      },
      "source": [
        "df_train['healthy']=0\n",
        "df_train['scab']=0\n",
        "df_train['complex']=0\n",
        "df_train['rust']=0\n",
        "df_train['frog_eye_leaf_spot']=0\n",
        "df_train['powdery_mildew']=0\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgXLh3lEreXz",
        "outputId": "9aa0977b-d453-4df9-e1fc-2cbe2feb54ee"
      },
      "source": [
        "for rown in range(0,len(df_train['labels'])):\n",
        "    for i in df_train['labels'][rown]:\n",
        "        if i == 'healthy':\n",
        "            df_train['healthy'][rown]=1\n",
        "        elif i == 'scab':\n",
        "            df_train['scab'][rown]=1\n",
        "        elif i == 'complex':\n",
        "            df_train['complex'][rown]=1\n",
        "        elif i == 'rust':\n",
        "            df_train['rust'][rown]=1\n",
        "        elif i == 'frog_eye_leaf_spot':\n",
        "            df_train['frog_eye_leaf_spot'][rown]=1\n",
        "        elif i == 'powdery_mildew':\n",
        "            df_train['powdery_mildew'][rown]=1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReJzoUgdrhKC",
        "outputId": "a00623ec-3f2d-465d-cd3c-f79451d49c11"
      },
      "source": [
        "df_train[['healthy','scab','complex','rust','frog_eye_leaf_spot','powdery_mildew']].sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "healthy               4624\n",
              "scab                  5712\n",
              "complex               2151\n",
              "rust                  2077\n",
              "frog_eye_leaf_spot    4352\n",
              "powdery_mildew        1271\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oWIG25r_QDE"
      },
      "source": [
        "Stoing the labels as 6 dimentional Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y73qKeMrkxn"
      },
      "source": [
        "y=np.asarray(df_train[['healthy','scab','complex','rust','frog_eye_leaf_spot','powdery_mildew']])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMP1fjlErpm0"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCE82xGJ_aiL"
      },
      "source": [
        "**Importing and Using InceptionV3 pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioJsYAZGrsBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00f8e17-10ee-4518-fd1d-ddf5534ccffa"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-04 14:17:33--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.23.128, 74.125.203.128, 74.125.204.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.23.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   184MB/s    in 0.5s    \n",
            "\n",
            "2021-08-04 14:17:33 (184 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M2j3Lgzr1q9"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(100, 100, 3), include_top=False, weights=None)\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmkZUgmVr7mF"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I5sCojlsBe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a9b7620-06e6-498f-f6e6-a7b5bf253623"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 4, 4, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqakas7qsGK6"
      },
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(6, activation='sigmoid')(x)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb9eNhecAAza"
      },
      "source": [
        "Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UWBzC66tYIk"
      },
      "source": [
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=\"binary_crossentropy\",\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPbJLY6GAFlR"
      },
      "source": [
        "Training model with data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH7x6G_fsPjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3121e79d-f3ea-4636-ed30-c9fae303bd37"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), batch_size=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "299/299 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.5435"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}